{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Before you start</h2>\n",
    "If this is a first time the pipeline is running on this machine, just run the cell below. This list of external libraries may not be full, in this case you may add required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy\n",
    "!pip install PySide6\n",
    "!pip install wgpu glfw\n",
    "!pip install fastplotlib\n",
    "!pip install jupyter_rfb\n",
    "!pip install sidecar\n",
    "!pip install sortedcontainers\n",
    "!pip install cmasher\n",
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Module 0</h2>\n",
    "This module is obligatory, run the cell below each time you (re)start kernel. Import libraries and specify the root folder.<br/>Also specify folder structure, where to search for miniscope videos, typically '\\Mouse_name\\date\\time\\Miniscope\\\\'. Note that * is a wildcard for any symbol combination except slashes (i.e., for any folder name), so it is strongly recommended to use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tkinter.filedialog import askopenfilenames, Tk\n",
    "from cd_batch_routines import *\n",
    "from cd_inspector_callbacks import *\n",
    "from cd_spike_detection import *\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "root = 'F:\\\\ROlga\\\\Rudy_old-young-11-2022_03-2023\\\\Video-for-check\\\\M27old\\\\'\n",
    "folder_structure = '*\\*\\Miniscope\\\\'  \n",
    "\n",
    "#This is needed for the proper work of furter manual file selection:\n",
    "wnd = Tk()\n",
    "wnd.wm_attributes('-topmost', 1)\n",
    "response = wnd.withdraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GncCQRjb7Olv"
   },
   "source": [
    "<h2>Module 1</h2>\n",
    "Manual video inspection. <br/>Open folder with miniscopic videos in a pop-up window, wait for loading and specify margins to be cropped by sliders or by keyboard, then save them by running the next cell. At the time, cropping .pickle files are to be created in these folders. Repeat for all folders with miniscopic videos you would like to analyze.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual file selection:\n",
    "fnames = list(askopenfilenames(title = 'Select files for inspection', initialdir = root, filetypes = [('AVI files', '.avi')]))\n",
    "#OR, alternatively, you can useAutomatic file selection\n",
    "#fnames = glob(root + folder_structure + '*.avi')\n",
    "\n",
    "data = LoadSelectedVideos(fnames)\n",
    "w = DrawCropper(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveCrops(os.path.dirname(fnames[0]), w.kwargs['left'], w.kwargs['up'], w.kwargs['right'], w.kwargs['down'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, you can use GUI based on fastplotlib library. Launch the cell below, open folder(s) with miniscopic videos in a pop-up window, wait for loading and specify margins to be cropped by dragging edges or by digits, then save them by pressing a button. At the time, cropping .pickle files are to be created in these folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CaDet-GUI/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQSrg0k7Ol7"
   },
   "source": [
    "Batch cropping and timestamp extraction.<br/>Miniscopic videos from folders with .pickle files are to be cropped and saved as _CR.tif in the root folder. There is no need for renaming of sigle-digit .avis (like 0-9.avi to 00-09.avi)!<br/>\n",
    "Also, along with video data, timestamps are to be copied from minicopic foolders to the root folder. Do not delete them, they are nessesary for the further steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Batch crop\n",
    "pick_names = glob(root + folder_structure + '*cropping.pickle')\n",
    "\n",
    "for name in pick_names:\n",
    "    DoCropAndRewrite(root, name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 2</h2>\n",
    "Batch motion correction.<br/>All _CR.tif files in the root folder are to be automatically motion corrected with NoRMCorre routine [Pnevmatikakis, Giovanucci, 2017] with the parameters below and saved as _MC.tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Automatic file selection\n",
    "fnames = glob(root + '*_CR.tif')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for motion correction', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "mc_dict = {\n",
    "    'pw_rigid': False,         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "    'max_shifts': (35, 35),    # maximum allowed rigid shift\n",
    "    'gSig_filt': (8, 8),       # size of high pass spatial filtering, used in 1p data\n",
    "    'strides': (48, 48),       # start a new patch for pw-rigid motion correction every x pixels\n",
    "    'overlaps': (24, 24),      # overlap between pathes (size of patch strides+overlaps)\n",
    "    'max_deviation_rigid': 15,  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "    'border_nan': 'copy',      # replicate values along the boundaries\n",
    "    'use_cuda': True,          # Set to True in order to use GPU\n",
    "    'memory_fact': 4,          # How much memory to allocate. 1 works for 16Gb, so 0.8 show be optimized for 12Gb.\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,          # for parallelization split the movies in  num_splits chuncks across time\n",
    "                               # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None} # intervals at which patches are laid out for motion correction  \n",
    "\n",
    "for name in fnames:\n",
    "    DoMotionCorrection(name, mc_dict)\n",
    "    CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Module 2.5 (optional)</h3>\n",
    "Pre-test of various values of <i>gSig</i> parameter, which is used in the Module 3 and corresponds to a typical radius of a neuron in pixels.<br/>You can play with this parameter but you can use the default value of gSig = 6 as well. <br/> Calculation may take a while, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(root + '*MC.tif')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for gSig testing', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "Test_gSig_Range(fnames[0])  \n",
    "# Test_gSig_Range(fnames[0], maxframes = 1000)  ## maxframes is the amount of frames taken into account, by default the whole file is to be taken, which may be too slow for large files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 3</h2>\n",
    "Batch cnmf.<br/>All _MC.tif files in the root folder are to be automatically processed with CaImAn routine [Giovanucci et al., 2019] with the parameters below. Main parameters are gSig and gSiz for cell augmentation, then min_SNR as traces quality threshold. At the end, _estimates.pickle files are to be produced in the root folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = glob(root + '*MC.tif')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for batch cnmf', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "cnmf_dict= {'fr': 20,                   # frame rate, frames per second\n",
    "            'decay_time': 2,            # typical duration of calcium transient \n",
    "            'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "            'K': None,                  # upper bound on number of components per patch, in general None\n",
    "            'gSig': (6, 6),             # gaussian HALF-width of a 2D gaussian kernel (in pixels), which approximates a neuron\n",
    "            'gSiz': (10, 10),           # maximal radius of a neuron in pixels\n",
    "            'merge_thr': 0.85,          # merging threshold, max correlation allowed\n",
    "            'p': 1,                     # order of the autoregressive system\n",
    "            'tsub': 1,                  # downsampling factor in time for initialization\n",
    "            'ssub': 1,                  # downsampling factor in space for initialization\n",
    "            'rf': 30,                   # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "            'stride': 25,               # amount of overlap between the patches in pixels(keep it at least large as gSiz, i.e 4 times the neuron size gSig) \n",
    "            'only_init': True,          # set it to True to run CNMF-E\n",
    "            'nb': 0,                    # number of background components (rank) if positive, else exact ring model with following settings: nb= 0: Return background as b and W, gnb=-1: Return full rank background B, gnb<-1: Don't return background\n",
    "            'nb_patch': 0,              # number of background components (rank) per patch if nb>0, else it is set automatically\n",
    "            'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "            'low_rank_background': None,           # None leaves background of each patch intact, True performs global low-rank approximation if gnb>0\n",
    "            'update_background_components': True,  # sometimes setting to False improve the results\n",
    "            'min_corr': .8,                        # min peak value from correlation image\n",
    "            'min_pnr': 10,                         # min peak to noise ratio from PNR image\n",
    "            'normalize_init': False,               # just leave as is\n",
    "            'center_psf': True,                    # leave as is for 1 photon\n",
    "            'ssub_B': 2,                           # additional downsampling factor in space for background\n",
    "            'ring_size_factor': 1.5,               # radius of ring is gSiz*ring_size_factor\n",
    "            'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "            'border_pix': 5,                       # number of pixels to not consider in the borders\n",
    "            'min_SNR': 1,                          # adaptive way to set threshold on the transient size\n",
    "            'rval_thr': 0.5,                       # threshold on space consistency           \n",
    "            'use_cnn': False}                      # whether to use CNNs for event detection  \n",
    "\n",
    "for name in fnames:\n",
    "    DoCNMF(name, cnmf_dict)\n",
    "    CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnAjhqtm7Ol8"
   },
   "source": [
    "<h2>Module 4</h2>\n",
    "User inspection of cnmf results.<br/>\n",
    "First you need to load estimates files which contain results of cnmfe analysis.\n",
    "Btw, at this stage, previously saved timestamps are to be merged with cnmf results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1676497043313,
     "user": {
      "displayName": "Vladimir Sotskov",
      "userId": "01718249932043625864"
     },
     "user_tz": -180
    },
    "id": "-P4TDWHe7Ol8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stuff needed for plotting and widget callbacks\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import LinearColorMapper, CDSView, ColumnDataSource, Plot, CustomJS, Button, IndexFilter\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.io import push_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "est_fnames = glob(root + '*estimates.pickle')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#est_fnames = askopenfilenames(title = 'Select estimates files for inspection', initialdir = root, filetypes = [('estimates files', '*estimates.pickle')])\n",
    "\n",
    "est = LoadEstimates(est_fnames[0])\n",
    "p1, p2, src, pts_src = DrawFigures(est)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, by running the section below, you will be prompted to interactively select detected units (you can select both spatial and temporal components), you can merge and delete them, also you can seed new neurons (by PointDrawTool) for further re-run of CNMF with saved seeds. Finally, you can save (by pressing 'Save Results') spatial and temporal components as .tif and traces.csv files, respectively. Spatial components (aka filters) are to be stored in a separate folder. For switching to the next file you selected in the section above, press 'LoadNextData' button and re-run this section again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plotting itself\n",
    "button_load = Button(label=\"Load next data\", button_type=\"success\", width = 120)     \n",
    "button_load.js_on_event('button_click', CustomJS(code=\"\"\"\n",
    "     var kernel = IPython.notebook.kernel;\n",
    "     kernel.execute(\"i = i + 1\");\n",
    "     kernel.execute(\"est = LoadEstimates(est_fnames[i])\");\n",
    "     kernel.execute(\"p1, p2, src, pts_src = DrawFigures(est)\")\n",
    "     kernel.execute(\"show(column(row(button_load, button_del, button_merge, button_seed, button_save), row(p1, p2)))\")\n",
    "     \"\"\")) \n",
    "\n",
    "button_del = Button(label=\"Delete selected\", button_type=\"success\", width = 120)     \n",
    "button_del.js_on_event('button_click', CustomJS(args=dict(src = src), code=\"\"\"\n",
    "     var si = src.selected.indices;\n",
    "     var kernel = IPython.notebook.kernel;\n",
    "     kernel.execute(\"ind_to_del= \" + si);\n",
    "     kernel.execute(\"est = DeleteSelected(est, ind_to_del)\");\n",
    "     kernel.execute(\"src.data = EstimatesToSrc(est)\");\n",
    "     kernel.execute(\"push_notebook(handle = t)\") \"\"\")) \n",
    "\n",
    "button_merge = Button(label=\"Merge selected\", button_type=\"success\", width = 120)     \n",
    "button_merge.js_on_event('button_click', CustomJS(args=dict(src = src), code=\"\"\"\n",
    "     var si = src.selected.indices;\n",
    "     var kernel = IPython.notebook.kernel;\n",
    "     kernel.execute(\"ind_to_mrg = \" + si);\n",
    "     kernel.execute(\"est = MergeSelected(est, ind_to_mrg, opts)\");\n",
    "     kernel.execute(\"src.data = EstimatesToSrc(est)\");\n",
    "     kernel.execute(\"push_notebook(handle = t)\") \"\"\"))  \n",
    "\n",
    "button_seed = Button(label=\"Save seeds\", button_type=\"success\", width = 120)     \n",
    "button_seed.js_on_event('button_click', CustomJS(args=dict(src = pts_src), code=\"\"\"\n",
    "     var sx = src.data['x'];\n",
    "     var sy = src.data['y'];\n",
    "     var kernel = IPython.notebook.kernel;\n",
    "     kernel.execute(\"seeds = [[\" + sx + \"],[\" + sy + \"]]\");\n",
    "     kernel.execute(\"SaveSeeds(seeds, base_name = est.name.partition('_estimates')[0])\")\"\"\"))\n",
    "\n",
    "button_save = Button(label=\"Save results\", button_type=\"success\", width = 120)\n",
    "button_save.js_on_event('button_click', CustomJS(code=\"\"\"\n",
    "     var kernel = IPython.notebook.kernel;\n",
    "     kernel.execute(\"SaveResults(est)\") \"\"\"))\n",
    "\n",
    "t = show(column(row(button_load, button_del, button_merge, button_seed, button_save), row(p1, p2)), notebook_handle = 'True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo cnmf with manually added seeds (optional).<br/>\n",
    "NB!! By running this cell, you will rewrite existing estimates files!!<br/>\n",
    "Then you can return to the section above and inspect the rewritten estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_names = glob(root + '*seeds.pickle')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#s_names = askopenfilenames(title = 'Select seeds files for re-CNMFing', initialdir = root, filetypes = [('seeds files', '*seeds.pickle')])\n",
    "\n",
    "for s_name in s_names:\n",
    "    e_names = glob(s_name.partition('_seeds')[0] + '_estimates.pickle')\n",
    "    ReDoCNMF(s_name, e_names[0])\n",
    "    CleanMemmaps(s_name.partition('_seeds')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G08W3pnX7OmB"
   },
   "source": [
    "<h2>Module 5</h2>\n",
    "Batch event detection. <br/>\n",
    "INPUT: (timestamped) cnmf raw traces as *_traces.csv files<br/>\n",
    "OUTPUT: detected events as *_spikes.csv files; pickles with events (cell-wise list of event-wise lists with dictionaries) and also, interactive .html plot with traces and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0eeQDMs7OmB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select traces for event detection', initialdir = root, filetypes = [('traces files', '*traces.csv')])\n",
    "\n",
    "sd_dict = {'thr': 4,        #threshold for peaks in Median Absolute Deviations (MADs)                   \n",
    "           'sigma' : 7,     #smoothing parameter for peak detection, frames\n",
    "           'est_ton' : 0.5, #estimated event rising time, s\n",
    "           'est_toff' : 2,  #estimated event decay time, s\n",
    "           'draw_details': True} #whether to draw smoothed traces, peaks, pits and fits \n",
    "\n",
    "for name in fnames:\n",
    "    FitEvents(name, opts = sd_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, just in case, you may draw existed pairs of traces and spikes right here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "for name in fnames:\n",
    "    DrawSpEvents(name, name.replace('traces','spikes'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sandbox</h2>\n",
    "Some potentially interesting snippets, for development purpose only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks_cwt\n",
    "import numpy as np\n",
    "root = 'F:\\ROlga\\Rudy_old-young-11-2022_03-2023\\Video-for-check\\M27old\\\\'\n",
    "trace = np.genfromtxt(root + 'M27old_2023_03_21_14_14_49_CR_MC_traces.csv', delimiter = ',', skip_header = 1)[:2000,1]\n",
    "time = np.genfromtxt(root + 'M27old_2023_03_21_14_14_49_CR_MC_traces.csv', delimiter = ',', skip_header = 1)[:2000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(time, trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_pos = find_peaks_cwt(trace, widths=[1.8], wavelet=None, max_distances=None, gap_thresh=None, min_length=None, min_snr=1, noise_perc=10, window_size=None)\n",
    "peaks_neg = find_peaks_cwt(-trace, widths=[1.8], wavelet=None, max_distances=None, gap_thresh=None, min_length=None, min_snr=1, noise_perc=10, window_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "plt.plot(time, trace)\n",
    "plt.scatter(time[peaks_pos], trace[peaks_pos], color = 'r')\n",
    "plt.scatter(time[peaks_neg], trace[peaks_neg], color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(pcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(EventForm, time[560:700], trace[560:700], p0 = [thr, trace[560], time[560],1,5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (20,5))\n",
    "plt.plot(time[560:700], trace[560:700])\n",
    "plt.plot(time[560:700], EventForm(time[560:700], *popt))\n",
    "#plt.plot(time, EventForm(time, 10, 20, 30, 1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stuff needed for plotting and widget callbacks\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import LinearColorMapper, CDSView, ColumnDataSource, Plot, CustomJS, Button, IndexFilter\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.io import push_notebook\n",
    "import os\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from json import load as j_load\n",
    "from glob import glob\n",
    "\n",
    "#first, it's needed to calculate maximal projection image\n",
    "def get_maximum_projection_from_json(j_name):\n",
    "    # This function loads videos using moviepy\n",
    "    with open(j_name,) as f:\n",
    "        j_data = j_load(f)\n",
    "    res = np.zeros((j_data['ROI']['height'], j_data['ROI']['width']))\n",
    "    avi_names = glob(os.path.dirname(j_name) + '\\\\*.avi')                   \n",
    "                      \n",
    "    for avi_name in avi_names:\n",
    "        clip = VideoFileClip(str(avi_name))\n",
    "        for frame in clip.iter_frames():\n",
    "            res = np.maximum(res, frame[:,:,0])\n",
    "    return res\n",
    "\n",
    "def get_pnr_image(data, gSig):\n",
    "     _, pnr = cm.summary_images.correlation_pnr(data[::5], gSig=gSig, swap_dim=False)\n",
    "\n",
    "\n",
    "root = 'C:\\\\Miniscope_v4_Data\\\\FAD_mice\\\\BE_1\\\\2022_09_09\\\\15_13_33\\\\Miniscope\\\\'\n",
    "j_name = glob(root + '*.json')\n",
    "\n",
    "res = get_maximum_projection_from_json(j_name[0])\n",
    "\n",
    "plt.imshow(res)\n",
    "\n",
    "#tools1 = [\"pan\",\"tap\",\"box_select\",\"zoom_in\",\"zoom_out\",\"reset\"]\n",
    "\n",
    "#p1 = figure(width = imwidth, height = height, tools = tools1, toolbar_location = 'below', title = title)\n",
    "#p1.image(image=[estimates.imax], color_mapper=color_mapper, dh = dims[0], dw = dims[1], x=0, y=0)\n",
    "#t = show(column(row(button_load, button_del, button_merge, button_seed, button_save), row(p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "\n",
    "def DrawCropper(data, dpi=200):\n",
    "    \n",
    "    play = ipw.Play(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=data.shape[0]-1,\n",
    "        step=1,\n",
    "        interval=50,\n",
    "        disabled=False\n",
    "    )\n",
    "    x_slider = ipw.IntSlider(layout=ipw.Layout(width='75%'))\n",
    "    ipw.jslink((play, 'value'), (x_slider, 'value'))\n",
    "    \n",
    "    l_slider = ipw.IntSlider(value=50, min=0, max=data.shape[1]-1)\n",
    "    u_slider = ipw.IntSlider(value=50, min=0, max=data.shape[2]-1)\n",
    "    r_slider = ipw.IntSlider(value=50, min=0, max=data.shape[1]-1)\n",
    "    d_slider = ipw.IntSlider(value=50, min=0, max=data.shape[2]-1)\n",
    "    \n",
    "    def update_right(*args):\n",
    "        r_slider.max = data.shape[1] - l_slider.value -1 \n",
    "    l_slider.observe(update_right, 'value')\n",
    "    \n",
    "    def update_down(*args):\n",
    "        d_slider.max = data.shape[2] - u_slider.value -1\n",
    "    u_slider.observe(update_down, 'value')\n",
    "    \n",
    "    w = ipw.interactive(DrawFrameAndBox, data = ipw.fixed(data), x = x_slider, left = l_slider, up = u_slider, right = r_slider, down = d_slider, dpi = ipw.fixed(200))\n",
    "    display(w)\n",
    "    ipw.HBox([play, x_slider])\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0425e94652264a39ab474dac975c6b86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f80f083a8d412ba98f094104f58a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704f6bdddae74c30a20cbcd2e3401a7c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0425e94652264a39ab474dac975c6b86",
      "msg_id": "",
      "outputs": []
     }
    },
    "74cb7943da364f88813682c21b185ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "835d7ae0d557435198ba1aec6c9391ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c78ea570615644abacd263f0cd68dcc7",
       "IPY_MODEL_d034447370f049b695e7587856fbcada"
      ],
      "layout": "IPY_MODEL_74cb7943da364f88813682c21b185ef4"
     }
    },
    "84b51326a2f74869906ed95583092492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c78ea570615644abacd263f0cd68dcc7": {
     "model_module": "jupyter_rfb",
     "model_module_version": "^0.1.0",
     "model_name": "RemoteFrameBufferModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter_rfb",
      "_model_module_version": "^0.1.0",
      "_model_name": "RemoteFrameBufferModel",
      "_view_count": null,
      "_view_module": "jupyter_rfb",
      "_view_module_version": "^0.1.0",
      "_view_name": "RemoteFrameBufferView",
      "css_height": "300px",
      "css_width": "500px",
      "frame_feedback": {},
      "has_visible_views": false,
      "layout": "IPY_MODEL_7aad0af5bc3441f5ac84d3c4a49067f9",
      "resizable": true
     }
    },
    "d034447370f049b695e7587856fbcada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "dimension: t",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_30f80f083a8d412ba98f094104f58a58",
      "max": 499,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_84b51326a2f74869906ed95583092492",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
