{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Before you start</h2>\n",
    "If this is the first time the pipeline is running on this machine, just run the cell below. It will copy startup.py from the BEARMIND folder into your local startup folder. This allows the code in startup.py to be executed automatically after each kernel restart (and removes the need to monotonously click through all setup cells after each reloading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\1\\\\.ipython\\\\profile_default\\\\startup\\\\startup.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "local_startup_dir = get_ipython().profile_dir.startup_dir\n",
    "filedir = os.getcwd()\n",
    "shutil.copy(os.path.join(filedir, 'startup.py'), os.path.join(local_startup_dir, 'startup.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Module 0</h2>\n",
    "You need to specify the root folder and pathway pattern. Note that * is a wildcard for any symbol combination except slashes (i.e., for any folder name), so it is strongly recommended to use it here.<br/><br/>\n",
    "NB!! Just in case, use double backslashes for folder separation, otherwise some symbols may be interpreted as escape sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:\\\\Users\\\\1\\\\HM_NOF_4D'\n",
    "pathway = 'bonsai'\n",
    "\n",
    "#write_to_config(root, pathway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\1\\\\HM_NOF_4D'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GncCQRjb7Olv"
   },
   "source": [
    "<h2>Module 1</h2>\n",
    "Manual video inspection. <br/>Open folder with miniscopic videos in a pop-up window, wait for loading and specify margins to be cropped by sliders or by keyboard, then save them by running the next cell. At the time, cropping .pickle files are to be created in these folders. Repeat for all folders with miniscopic videos you would like to analyze.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dce34a90cb4f379ddbf1478342948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='x', layout=Layout(width='100%'), max=999), IntSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Manual file selection:\n",
    "fnames = list(askopenfilenames(title = 'Select files for inspection', initialdir = config.ROOT, filetypes = [('AVI files', '.avi')]))\n",
    "#OR, alternatively, you can use Automatic file selection\n",
    "#fnames = glob(config.ROOT + folder_structure + '*.avi')\n",
    "\n",
    "data = LoadSelectedVideos(fnames)\n",
    "w = DrawCropper(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LEFT': 50, 'RIGHT': 50, 'UP': 50, 'DOWN': 50}\n",
      "Crops saved to C:\\Users\\1\\HM_NOF_4D\\NOF_H01_4D\\NOF_H01_4D_l=50_r=50_u=50_d=50_cropping.pickle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SaveCrops(fnames[0], w.kwargs['left'], w.kwargs['right'], w.kwargs['up'], w.kwargs['down'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQSrg0k7Ol7"
   },
   "source": [
    "Batch cropping and timestamp extraction.<br/>Miniscopic videos from folders with .pickle files are to be cropped and saved as _CR.tif in the root folder. There is no need for renaming of sigle-digit .avi files (like 0-9.avi to 00-09.avi)!<br/>\n",
    "Also, along with video data, timestamps are to be copied from minicopic folders to the root folder. Do not delete them, they are nessesary for the further steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:17<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_4D_CR.tif cropped in 23.7s\n"
     ]
    }
   ],
   "source": [
    "#Batch crop\n",
    "cpath_template = os.path.normpath(os.path.join(config.ROOT, folder_structure, '*cropping.pickle'))\n",
    "pick_names = glob(cpath_template)\n",
    "\n",
    "for name in pick_names:\n",
    "    DoCropAndRewrite(name)\n",
    "    extract_and_copy_ts(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 2</h2>\n",
    "Batch motion correction.<br/>All _CR.tif files in the root folder are to be automatically motion corrected with NoRMCorre routine [Pnevmatikakis, Giovanucci, 2017] with the parameters below and saved as _MC.tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "  0%|          | 0/1 [04:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 583. MiB for an array with shape (592, 508, 508) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\1\\anaconda3\\envs\\caiman\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\1\\anaconda3\\envs\\caiman\\lib\\multiprocessing\\pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"C:\\Users\\1\\anaconda3\\envs\\caiman\\lib\\site-packages\\caiman\\motion_correction.py\", line 3117, in tile_and_correct_wrapper\n    mc.astype(np.float32), (len(imgs), -1), order='F').T + bias\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 583. MiB for an array with shape (592, 508, 508) and data type float32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m      6\u001b[0m mc_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpw_rigid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,         \u001b[38;5;66;03m# flag for performing piecewise-rigid motion correction (otherwise just rigid)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_shifts\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m35\u001b[39m),    \u001b[38;5;66;03m# maximum allowed rigid shift\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m                                \u001b[38;5;66;03m# if none all the splits are processed and the movie is saved\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_splits_to_process_rig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;66;03m# intervals at which patches are laid out for motion correction  \u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(fnames):\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mDoMotionCorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     CleanMemmaps(name)\n",
      "File \u001b[1;32m~\\PycharmProjects\\bearmind\\bm_batch_routines.py:180\u001b[0m, in \u001b[0;36mDoMotionCorrection\u001b[1;34m(name, mc_dict)\u001b[0m\n\u001b[0;32m    177\u001b[0m opts \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mCNMFParams(params_dict\u001b[38;5;241m=\u001b[39mmc_dict)\n\u001b[0;32m    179\u001b[0m mc \u001b[38;5;241m=\u001b[39m MotionCorrect([name], dview\u001b[38;5;241m=\u001b[39mdview, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts\u001b[38;5;241m.\u001b[39mget_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotion\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 180\u001b[0m \u001b[43mmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmotion_correct\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m fname_mc \u001b[38;5;241m=\u001b[39m mc\u001b[38;5;241m.\u001b[39mfname_tot_els \u001b[38;5;28;01mif\u001b[39;00m mc\u001b[38;5;241m.\u001b[39mpw_rigid \u001b[38;5;28;01melse\u001b[39;00m mc\u001b[38;5;241m.\u001b[39mfname_tot_rig\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mc\u001b[38;5;241m.\u001b[39mpw_rigid:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\caiman\\lib\\site-packages\\caiman\\motion_correction.py:262\u001b[0m, in \u001b[0;36mMotionCorrect.motion_correct\u001b[1;34m(self, template, save_movie)\u001b[0m\n\u001b[0;32m    259\u001b[0m         b0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mmaximum(np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_shifts_els)),\n\u001b[0;32m    260\u001b[0m                             np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_shifts_els))))\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmotion_correct_rigid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_movie\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     b0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshifts_rig)))\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mborder_to_0 \u001b[38;5;241m=\u001b[39m b0\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\caiman\\lib\\site-packages\\caiman\\motion_correction.py:296\u001b[0m, in \u001b[0;36mMotionCorrect.motion_correct_rigid\u001b[1;34m(self, template, save_movie)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshifts_rig:List \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname_cur \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname:\n\u001b[1;32m--> 296\u001b[0m     _fname_tot_rig, _total_template_rig, _templates_rig, _shifts_rig \u001b[38;5;241m=\u001b[39m \u001b[43mmotion_correct_batch_rigid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname_cur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_shifts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplits_rig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_splits_to_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_splits_to_process_rig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mniter_rig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_template_rig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshifts_opencv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshifts_opencv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_movie_rigid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_movie\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_to_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_mov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnonneg_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonneg_movie\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgSig_filt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgSig_filt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mborder_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mborder_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_name_hdf5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_name_hdf5\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis3D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_template_rig \u001b[38;5;241m=\u001b[39m _total_template_rig\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\caiman\\lib\\site-packages\\caiman\\motion_correction.py:2879\u001b[0m, in \u001b[0;36mmotion_correct_batch_rigid\u001b[1;34m(fname, max_shifts, dview, splits, num_splits_to_process, num_iter, template, shifts_opencv, save_movie_rigid, add_to_movie, nonneg_movie, gSig_filt, subidx, use_cuda, border_nan, var_name_hdf5, is3D, indices)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2877\u001b[0m     base_name\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(fname)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_rig_\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 2879\u001b[0m fname_tot_rig, res_rig \u001b[38;5;241m=\u001b[39m \u001b[43mmotion_correction_piecewise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2880\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43madd_to_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_templ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shifts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shifts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_deviation_rigid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2881\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mdview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdview\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubidx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2882\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mnum_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_splits_to_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshifts_opencv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshifts_opencv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonneg_movie\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnonneg_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgSig_filt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgSig_filt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2883\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborder_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mborder_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name_hdf5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name_hdf5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis3D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2884\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is3D:\n\u001b[0;32m   2886\u001b[0m     new_templ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmedian(np\u001b[38;5;241m.\u001b[39mstack([r[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res_rig]), \u001b[38;5;241m0\u001b[39m)           \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\caiman\\lib\\site-packages\\caiman\\motion_correction.py:3194\u001b[0m, in \u001b[0;36mmotion_correction_piecewise\u001b[1;34m(fname, splits, strides, overlaps, add_to_movie, template, max_shifts, max_deviation_rigid, newoverlaps, newstrides, upsample_factor_grid, order, dview, save_movie, base_name, subidx, num_splits, shifts_opencv, nonneg_movie, gSig_filt, use_cuda, border_nan, var_name_hdf5, is3D, indices)\u001b[0m\n\u001b[0;32m   3192\u001b[0m     dview\u001b[38;5;241m.\u001b[39mmap(close_cuda_process, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pars)))\n\u001b[0;32m   3193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(dview)):\n\u001b[1;32m-> 3194\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mdview\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_and_correct_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpars\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4294967\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3196\u001b[0m     res \u001b[38;5;241m=\u001b[39m dview\u001b[38;5;241m.\u001b[39mmap_sync(tile_and_correct_wrapper, pars)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\caiman\\lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 583. MiB for an array with shape (592, 508, 508) and data type float32"
     ]
    }
   ],
   "source": [
    "#Automatic file selection\n",
    "fnames = glob(os.path.join(config.ROOT, '*_CR.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for motion correction', initialdir = config.ROOT, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "mc_dict = {\n",
    "    'pw_rigid': False,         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "    'max_shifts': (35, 35),    # maximum allowed rigid shift\n",
    "    'gSig_filt': (8, 8),       # size of high pass spatial filtering, used in 1p data\n",
    "    'strides': (48, 48),       # start a new patch for pw-rigid motion correction every x pixels\n",
    "    'overlaps': (24, 24),      # overlap between pathes (size of patch strides+overlaps)\n",
    "    'max_deviation_rigid': 15,  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "    'border_nan': 'copy',      # replicate values along the boundaries\n",
    "    'use_cuda': True,          # Set to True in order to use GPU\n",
    "    'memory_fact': 4,          # How much memory to allocate. 1 works for 16Gb, so 0.8 showd be optimized for 12Gb.\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,          # for parallelization split the movies in  num_splits chuncks across time\n",
    "                               # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None} # intervals at which patches are laid out for motion correction  \n",
    "\n",
    "for name in tqdm.tqdm(fnames):\n",
    "    DoMotionCorrection(name, mc_dict)\n",
    "    CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Module 2.5 (optional)</h3>\n",
    "Pre-test of various values of <i>gSig</i> parameter, which is used in the Module 3 and corresponds to a typical radius of a neuron in pixels.<br/>You can play with this parameter but you can use the default value of gSig = 6 as well. <br/> Calculation may take a while, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(os.path.join(config.ROOT, '*_MC.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for gSig testing', initialdir = config.ROOT, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "#Test_gSig_Range(fnames[0])\n",
    "Test_gSig_Range(fnames[0], maxframes = 1000)  ## maxframes is the amount of frames taken into account, by default the whole file is to be taken, which may be too slow for large files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 3</h2>\n",
    "Batch cnmf.<br/>All _MC.tif files in the root folder are to be automatically processed with CaImAn routine [Giovanucci et al., 2019] with the parameters below. Main parameters are gSig and gSiz for cell augmentation, then min_SNR as traces quality threshold. At the end, _estimates.pickle files are to be produced in the root folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:17<01:17, 77.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 77.2s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:01<00:00, 90.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 104.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:24<01:24, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 84.1s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:14<00:00, 97.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 110.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:24<01:24, 84.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 84.9s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:19<00:00, 99.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 114.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fnames = glob(os.path.join(config.ROOT, '*_MC.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for batch cnmf', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "cnmf_dict= {'fr': 20,                   # frame rate, frames per second (NOW RECALCULATED FOR EACH FILE FROM TIMESTAMP DATA)\n",
    "            'decay_time': 2,            # typical duration of calcium transient \n",
    "            'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "            'K': None,                  # upper bound on number of components per patch, in general None\n",
    "            'gSig': (6, 6),             # gaussian HALF-width of a 2D gaussian kernel (in pixels), which approximates a neuron\n",
    "            'gSiz': (10, 10),           # maximal radius of a neuron in pixels\n",
    "            'merge_thr': 0.85,          # merging threshold, max correlation allowed\n",
    "            'p': 1,                     # order of the autoregressive system\n",
    "            'tsub': 1,                  # downsampling factor in time for initialization\n",
    "            'ssub': 1,                  # downsampling factor in space for initialization\n",
    "            'rf': 30,                   # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "            'stride': 25,               # amount of overlap between the patches in pixels(keep it at least large as gSiz, i.e 4 times the neuron size gSig) \n",
    "            'only_init': True,          # set it to True to run CNMF-E\n",
    "            'nb': 0,                    # number of background components (rank) if positive, else exact ring model with following settings: nb= 0: Return background as b and W, gnb=-1: Return full rank background B, gnb<-1: Don't return background\n",
    "            'nb_patch': 0,              # number of background components (rank) per patch if nb>0, else it is set automatically\n",
    "            'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "            'low_rank_background': None,           # None leaves background of each patch intact, True performs global low-rank approximation if gnb>0\n",
    "            'update_background_components': True,  # sometimes setting to False improve the results\n",
    "            'min_corr': .8,                        # min peak value from correlation image\n",
    "            'min_pnr': 10,                         # min peak to noise ratio from PNR image\n",
    "            'normalize_init': False,               # just leave as is\n",
    "            'center_psf': True,                    # leave as is for 1 photon\n",
    "            'ssub_B': 2,                           # additional downsampling factor in space for background\n",
    "            'ring_size_factor': 1.5,               # radius of ring is gSiz*ring_size_factor\n",
    "            'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "            'border_pix': 5,                       # number of pixels to not consider in the borders\n",
    "            'min_SNR': 1,                          # adaptive way to set threshold on the transient size\n",
    "            'rval_thr': 0.5,                       # threshold on space consistency           \n",
    "            'use_cnn': False}                      # whether to use CNNs for event detection  \n",
    "\n",
    "\n",
    "start_frame = 100\n",
    "end_frame = 300\n",
    "\n",
    "for gsig in [6,7,8]:\n",
    "    cnmf_dict.update({'gSig': (gsig, gsig)})\n",
    "    \n",
    "    for name in tqdm.tqdm(fnames):\n",
    "        fps = get_fps_from_timestamps(name[:-4-6], default_fps=20, verbose=False)\n",
    "        cnmf_dict.update({'fr': fps})\n",
    "        out_name = name[:-4] + f'_gsig={gsig}'\n",
    "        \n",
    "        DoCNMF(name,\n",
    "               cnmf_dict,\n",
    "               out_name=out_name,\n",
    "               start_frame=start_frame,\n",
    "               end_frame=end_frame,\n",
    "               verbose=True)\n",
    "        \n",
    "        CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnAjhqtm7Ol8"
   },
   "source": [
    "<h2>Module 4</h2>\n",
    "User inspection of cnmf results.<br/>\n",
    "Btw, at this stage, previously saved timestamps are to be merged with cnmf results.\n",
    "By running the section below, you will be prompted to select estimtes file with cnmf results and then to interactively examine detected units (you can select both spatial and temporal components), you can select, merge and delete them, also you can seed new neurons (by PointDrawTool) for further re-run of CNMF with saved seeds. Finally, you can save (by pressing 'Save Results') spatial and temporal components as .tif and traces.csv files, respectively. Spatial components (aka filters) are to be stored in a separate folder (*_filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = askopenfilename(title = 'Select estimates file for examination', initialdir = config.ROOT, filetypes = [('estimates files', '*estimates.pickle')])\n",
    "\n",
    "bkapp_kwargs = {\n",
    "    'fill_alpha': 0.5,       # selected neuron transparency\n",
    "    'ns_alpha': 0.2,         # non-selected neuron transparency\n",
    "    'line_width': 2,         # border width\n",
    "    'cthr': 0.8              # coutour_thr from caiman (% of signal inside a patch), affects patch size\n",
    "}\n",
    "\n",
    "ExamineCells(fname, default_fps=20, bkapp_kwargs=bkapp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell in case of \"Refusing websocket connection...\" error in the cell above\n",
    "os.environ[\"BOKEH_ALLOW_WS_ORIGIN\"] = 'localhost:8888' #replace the port number with the actual one from the address string of your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo cnmf with manually added seeds (optional).<br/>\n",
    "NB!! By running the cell below, you will rewrite existing estimates files!!<br/>\n",
    "Then you can return to the section above and inspect the rewritten estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_names = glob(os.path.join(config.ROOT, '*seeds.pickle'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#s_names = askopenfilenames(title = 'Select seeds files for re-CNMFing', initialdir = root, filetypes = [('seeds files', '*seeds.pickle')])\n",
    "\n",
    "for s_name in s_names:\n",
    "    e_names = glob(s_name.partition('_seeds')[0] + '_estimates.pickle')\n",
    "    ReDoCNMF(s_name, e_names[0])\n",
    "    CleanMemmaps(s_name.partition('_seeds')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G08W3pnX7OmB"
   },
   "source": [
    "<h2>Module 5</h2>\n",
    "Batch event detection. <br/>\n",
    "INPUT: (timestamped) cnmf raw traces as *_traces.csv files<br/>\n",
    "OUTPUT: detected events as *_spikes.csv files; pickles with events (cell-wise list of event-wise lists with dictionaries) and also, interactive .html plot with traces and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0eeQDMs7OmB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = glob(config.ROOT + '*traces.csv')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select traces for event detection', initialdir = root, filetypes = [('traces files', '*traces.csv')])\n",
    "\n",
    "sd_dict = {'thr': 4,        #threshold for peaks in Median Absolute Deviations (MADs)                   \n",
    "           'sigma' : 7,     #smoothing parameter for peak detection, frames\n",
    "           'est_ton' : 0.5, #estimated event rising time, s\n",
    "           'est_toff' : 2,  #estimated event decay time, s\n",
    "           'draw_details': True} #whether to draw smoothed traces, peaks, pits and fits \n",
    "\n",
    "for name in fnames:\n",
    "    FitEvents(name, opts = sd_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, just in case, you may draw existed pairs of traces and spikes right here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(config.ROOT + '*traces.csv')\n",
    "for name in fnames:\n",
    "    DrawSpEvents(name, name.replace('traces','spikes'))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0425e94652264a39ab474dac975c6b86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f80f083a8d412ba98f094104f58a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704f6bdddae74c30a20cbcd2e3401a7c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0425e94652264a39ab474dac975c6b86",
      "msg_id": "",
      "outputs": []
     }
    },
    "74cb7943da364f88813682c21b185ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "835d7ae0d557435198ba1aec6c9391ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c78ea570615644abacd263f0cd68dcc7",
       "IPY_MODEL_d034447370f049b695e7587856fbcada"
      ],
      "layout": "IPY_MODEL_74cb7943da364f88813682c21b185ef4"
     }
    },
    "84b51326a2f74869906ed95583092492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c78ea570615644abacd263f0cd68dcc7": {
     "model_module": "jupyter_rfb",
     "model_module_version": "^0.1.0",
     "model_name": "RemoteFrameBufferModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter_rfb",
      "_model_module_version": "^0.1.0",
      "_model_name": "RemoteFrameBufferModel",
      "_view_count": null,
      "_view_module": "jupyter_rfb",
      "_view_module_version": "^0.1.0",
      "_view_name": "RemoteFrameBufferView",
      "css_height": "300px",
      "css_width": "500px",
      "frame_feedback": {},
      "has_visible_views": false,
      "layout": "IPY_MODEL_7aad0af5bc3441f5ac84d3c4a49067f9",
      "resizable": true
     }
    },
    "d034447370f049b695e7587856fbcada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "dimension: t",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_30f80f083a8d412ba98f094104f58a58",
      "max": 499,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_84b51326a2f74869906ed95583092492",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
