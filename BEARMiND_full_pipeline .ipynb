{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Before you start</h2>\n",
    "If this is a first time the pipeline is running on this machine, remove triple quotes and just run the cell below. This list of external libraries may not be full, in this case you may add required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install moviepy\\n!pip install PySide6\\n!pip install wgpu glfw\\n!pip install fastplotlib\\n!pip install jupyter_rfb\\n!pip install sidecar\\n!pip install sortedcontainers\\n!pip install cmasher\\n!pip install cv2\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install moviepy\n",
    "!pip install PySide6\n",
    "!pip install wgpu glfw\n",
    "!pip install fastplotlib\n",
    "!pip install jupyter_rfb\n",
    "!pip install sidecar\n",
    "!pip install sortedcontainers\n",
    "!pip install cmasher\n",
    "!pip install cv2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\.ipython\\\\profile_default\\\\startup'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ipython().profile_dir.startup_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Module 0</h2>\n",
    "This module is obligatory, run the cell below each time you (re)start kernel. </br>IYou need to specify the root folder and folder_structure pattern, where to search for miniscope videos, typically '\\\\Mouse_name\\\\date\\\\time\\Miniscope\\\\'. Note that * is a wildcard for any symbol combination except slashes (i.e., for any folder name), so it is strongly recommended to use it here.<br/><br/>\n",
    "NB!! Just in case, use double backslashes for folder separation, otherwise some symbols may be interpreted as escape sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://localhost:8888/', 'http://localhost:8889/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonsai'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATHWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GncCQRjb7Olv"
   },
   "source": [
    "<h2>Module 1</h2>\n",
    "Manual video inspection. <br/>Open folder with miniscopic videos in a pop-up window, wait for loading and specify margins to be cropped by sliders or by keyboard, then save them by running the next cell. At the time, cropping .pickle files are to be created in these folders. Repeat for all folders with miniscopic videos you would like to analyze.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual file selection:\n",
    "fnames = list(askopenfilenames(title = 'Select files for inspection', initialdir = root, filetypes = [('AVI files', '.avi')]))\n",
    "#OR, alternatively, you can use Automatic file selection\n",
    "#fnames = glob(root + folder_structure + '*.avi')\n",
    "\n",
    "data = LoadSelectedVideos(fnames)\n",
    "w = DrawCropper(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LEFT': 50, 'RIGHT': 50, 'UP': 50, 'DOWN': 50}\n",
      "Crops saved to C:\\Users\\Public\\IABS_DATA\\HM_NOF_2D\\NOF_H02_2D\\cropping.pickle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SaveCrops(os.path.dirname(fnames[0]), w.kwargs['left'], w.kwargs['right'], w.kwargs['up'], w.kwargs['down'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQSrg0k7Ol7"
   },
   "source": [
    "Batch cropping and timestamp extraction.<br/>Miniscopic videos from folders with .pickle files are to be cropped and saved as _CR.tif in the root folder. There is no need for renaming of sigle-digit .avi files (like 0-9.avi to 00-09.avi)!<br/>\n",
    "Also, along with video data, timestamps are to be copied from minicopic folders to the root folder. Do not delete them, they are nessesary for the further steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:24<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR.tif cropped in 33.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:24<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR.tif cropped in 32.9s\n"
     ]
    }
   ],
   "source": [
    "#Batch crop\n",
    "cpath_template = os.path.normpath(os.path.join(root, folder_structure, '*cropping.pickle'))\n",
    "pick_names = glob(cpath_template)\n",
    "\n",
    "for name in pick_names:\n",
    "    DoCropAndRewrite(root, name, pathway=DATA_PATHWAY)\n",
    "    extract_and_copy_ts(root, name, pathway=DATA_PATHWAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 2</h2>\n",
    "Batch motion correction.<br/>All _CR.tif files in the root folder are to be automatically motion corrected with NoRMCorre routine [Pnevmatikakis, Giovanucci, 2017] with the parameters below and saved as _MC.tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.73s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR.tif motion corrected in 300.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [05:02<05:02, 302.76s/it]WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "WARNING:root:Movie average is negative. Removing 1st percentile.\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR.tif motion corrected in 308.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [10:13<00:00, 307.00s/it]\n"
     ]
    }
   ],
   "source": [
    "#Automatic file selection\n",
    "fnames = glob(os.path.join(root, '*_CR.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for motion correction', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "mc_dict = {\n",
    "    'pw_rigid': False,         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "    'max_shifts': (35, 35),    # maximum allowed rigid shift\n",
    "    'gSig_filt': (8, 8),       # size of high pass spatial filtering, used in 1p data\n",
    "    'strides': (48, 48),       # start a new patch for pw-rigid motion correction every x pixels\n",
    "    'overlaps': (24, 24),      # overlap between pathes (size of patch strides+overlaps)\n",
    "    'max_deviation_rigid': 15,  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "    'border_nan': 'copy',      # replicate values along the boundaries\n",
    "    'use_cuda': True,          # Set to True in order to use GPU\n",
    "    'memory_fact': 4,          # How much memory to allocate. 1 works for 16Gb, so 0.8 showd be optimized for 12Gb.\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,          # for parallelization split the movies in  num_splits chuncks across time\n",
    "                               # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None} # intervals at which patches are laid out for motion correction  \n",
    "\n",
    "for name in tqdm.tqdm(fnames):\n",
    "    DoMotionCorrection(name, mc_dict)\n",
    "    CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Module 2.5 (optional)</h3>\n",
    "Pre-test of various values of <i>gSig</i> parameter, which is used in the Module 3 and corresponds to a typical radius of a neuron in pixels.<br/>You can play with this parameter but you can use the default value of gSig = 6 as well. <br/> Calculation may take a while, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(os.path.join(root, '*_MC.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for gSig testing', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "#Test_gSig_Range(fnames[0])\n",
    "Test_gSig_Range(fnames[0], maxframes = 1000)  ## maxframes is the amount of frames taken into account, by default the whole file is to be taken, which may be too slow for large files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 3</h2>\n",
    "Batch cnmf.<br/>All _MC.tif files in the root folder are to be automatically processed with CaImAn routine [Giovanucci et al., 2019] with the parameters below. Main parameters are gSig and gSiz for cell augmentation, then min_SNR as traces quality threshold. At the end, _estimates.pickle files are to be produced in the root folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:17<01:17, 77.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 77.2s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:01<00:00, 90.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 104.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:24<01:24, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 84.1s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:14<00:00, 97.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 110.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:24<01:24, 84.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H01_2D_CR_MC.tif cnmf-ed in 84.9s\n",
      "loading tif to memory...\n",
      "Performing CNMF...\n",
      "Computing imax...\n",
      "Saving result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:19<00:00, 99.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOF_H02_2D_CR_MC.tif cnmf-ed in 114.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fnames = glob(os.path.join(root, '*_MC.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for batch cnmf', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "cnmf_dict= {'fr': 20,                   # frame rate, frames per second (NOW RECALCULATED FOR EACH FILE FROM TIMESTAMP DATA)\n",
    "            'decay_time': 2,            # typical duration of calcium transient \n",
    "            'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "            'K': None,                  # upper bound on number of components per patch, in general None\n",
    "            'gSig': (6, 6),             # gaussian HALF-width of a 2D gaussian kernel (in pixels), which approximates a neuron\n",
    "            'gSiz': (10, 10),           # maximal radius of a neuron in pixels\n",
    "            'merge_thr': 0.85,          # merging threshold, max correlation allowed\n",
    "            'p': 1,                     # order of the autoregressive system\n",
    "            'tsub': 1,                  # downsampling factor in time for initialization\n",
    "            'ssub': 1,                  # downsampling factor in space for initialization\n",
    "            'rf': 30,                   # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "            'stride': 25,               # amount of overlap between the patches in pixels(keep it at least large as gSiz, i.e 4 times the neuron size gSig) \n",
    "            'only_init': True,          # set it to True to run CNMF-E\n",
    "            'nb': 0,                    # number of background components (rank) if positive, else exact ring model with following settings: nb= 0: Return background as b and W, gnb=-1: Return full rank background B, gnb<-1: Don't return background\n",
    "            'nb_patch': 0,              # number of background components (rank) per patch if nb>0, else it is set automatically\n",
    "            'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "            'low_rank_background': None,           # None leaves background of each patch intact, True performs global low-rank approximation if gnb>0\n",
    "            'update_background_components': True,  # sometimes setting to False improve the results\n",
    "            'min_corr': .8,                        # min peak value from correlation image\n",
    "            'min_pnr': 10,                         # min peak to noise ratio from PNR image\n",
    "            'normalize_init': False,               # just leave as is\n",
    "            'center_psf': True,                    # leave as is for 1 photon\n",
    "            'ssub_B': 2,                           # additional downsampling factor in space for background\n",
    "            'ring_size_factor': 1.5,               # radius of ring is gSiz*ring_size_factor\n",
    "            'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "            'border_pix': 5,                       # number of pixels to not consider in the borders\n",
    "            'min_SNR': 1,                          # adaptive way to set threshold on the transient size\n",
    "            'rval_thr': 0.5,                       # threshold on space consistency           \n",
    "            'use_cnn': False}                      # whether to use CNNs for event detection  \n",
    "\n",
    "\n",
    "start_frame = 100\n",
    "end_frame = 300\n",
    "\n",
    "for gsig in [6,7,8]:\n",
    "    cnmf_dict.update({'gSig': (gsig, gsig)})\n",
    "    \n",
    "    for name in tqdm.tqdm(fnames):\n",
    "        fps = get_fps_from_timestamps(name[:-4-6], default_fps=20, verbose=False)\n",
    "        cnmf_dict.update({'fr': fps})\n",
    "        out_name = name[:-4] + f'_gsig={gsig}'\n",
    "        \n",
    "        DoCNMF(name,\n",
    "               cnmf_dict,\n",
    "               out_name=out_name,\n",
    "               start_frame=start_frame,\n",
    "               end_frame=end_frame,\n",
    "               verbose=True)\n",
    "        \n",
    "        CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnAjhqtm7Ol8"
   },
   "source": [
    "<h2>Module 4</h2>\n",
    "User inspection of cnmf results.<br/>\n",
    "Btw, at this stage, previously saved timestamps are to be merged with cnmf results.\n",
    "By running the section below, you will be prompted to select estimtes file with cnmf results and then to interactively examine detected units (you can select both spatial and temporal components), you can select, merge and delete them, also you can seed new neurons (by PointDrawTool) for further re-run of CNMF with saved seeds. Finally, you can save (by pressing 'Save Results') spatial and temporal components as .tif and traces.csv files, respectively. Spatial components (aka filters) are to be stored in a separate folder (*_filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = askopenfilename(title = 'Select estimates file for examination', initialdir = root, filetypes = [('estimates files', '*estimates.pickle')])\n",
    "\n",
    "bkapp_kwargs = {\n",
    "    'pathway': DATA_PATHWAY, \n",
    "    'fill_alpha': 0.5,       # selected neuron transparency\n",
    "    'ns_alpha': 0.2,         # non-selected neuron transparency\n",
    "    'line_width': 2,         # border width\n",
    "    'cthr': 0.8              # coutour_thr from caiman (% of signal inside a patch), affects patch size\n",
    "}\n",
    "\n",
    "ExamineCells(fname, default_fps=20, bkapp_kwargs=bkapp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell in case of \"Refusing websocket connection...\" error in the cell above\n",
    "os.environ[\"BOKEH_ALLOW_WS_ORIGIN\"] = 'localhost:8888' #replace the port number with the actual one from the address string of your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo cnmf with manually added seeds (optional).<br/>\n",
    "NB!! By running the cell below, you will rewrite existing estimates files!!<br/>\n",
    "Then you can return to the section above and inspect the rewritten estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_names = glob(os.path.join(root, '*seeds.pickle'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#s_names = askopenfilenames(title = 'Select seeds files for re-CNMFing', initialdir = root, filetypes = [('seeds files', '*seeds.pickle')])\n",
    "\n",
    "for s_name in s_names:\n",
    "    e_names = glob(s_name.partition('_seeds')[0] + '_estimates.pickle')\n",
    "    ReDoCNMF(s_name, e_names[0])\n",
    "    CleanMemmaps(s_name.partition('_seeds')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G08W3pnX7OmB"
   },
   "source": [
    "<h2>Module 5</h2>\n",
    "Batch event detection. <br/>\n",
    "INPUT: (timestamped) cnmf raw traces as *_traces.csv files<br/>\n",
    "OUTPUT: detected events as *_spikes.csv files; pickles with events (cell-wise list of event-wise lists with dictionaries) and also, interactive .html plot with traces and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0eeQDMs7OmB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select traces for event detection', initialdir = root, filetypes = [('traces files', '*traces.csv')])\n",
    "\n",
    "sd_dict = {'thr': 4,        #threshold for peaks in Median Absolute Deviations (MADs)                   \n",
    "           'sigma' : 7,     #smoothing parameter for peak detection, frames\n",
    "           'est_ton' : 0.5, #estimated event rising time, s\n",
    "           'est_toff' : 2,  #estimated event decay time, s\n",
    "           'draw_details': True} #whether to draw smoothed traces, peaks, pits and fits \n",
    "\n",
    "for name in fnames:\n",
    "    FitEvents(name, opts = sd_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, just in case, you may draw existed pairs of traces and spikes right here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "for name in fnames:\n",
    "    DrawSpEvents(name, name.replace('traces','spikes'))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0425e94652264a39ab474dac975c6b86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f80f083a8d412ba98f094104f58a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704f6bdddae74c30a20cbcd2e3401a7c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0425e94652264a39ab474dac975c6b86",
      "msg_id": "",
      "outputs": []
     }
    },
    "74cb7943da364f88813682c21b185ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "835d7ae0d557435198ba1aec6c9391ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c78ea570615644abacd263f0cd68dcc7",
       "IPY_MODEL_d034447370f049b695e7587856fbcada"
      ],
      "layout": "IPY_MODEL_74cb7943da364f88813682c21b185ef4"
     }
    },
    "84b51326a2f74869906ed95583092492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c78ea570615644abacd263f0cd68dcc7": {
     "model_module": "jupyter_rfb",
     "model_module_version": "^0.1.0",
     "model_name": "RemoteFrameBufferModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter_rfb",
      "_model_module_version": "^0.1.0",
      "_model_name": "RemoteFrameBufferModel",
      "_view_count": null,
      "_view_module": "jupyter_rfb",
      "_view_module_version": "^0.1.0",
      "_view_name": "RemoteFrameBufferView",
      "css_height": "300px",
      "css_width": "500px",
      "frame_feedback": {},
      "has_visible_views": false,
      "layout": "IPY_MODEL_7aad0af5bc3441f5ac84d3c4a49067f9",
      "resizable": true
     }
    },
    "d034447370f049b695e7587856fbcada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "dimension: t",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_30f80f083a8d412ba98f094104f58a58",
      "max": 499,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_84b51326a2f74869906ed95583092492",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
