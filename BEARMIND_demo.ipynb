{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Before you start</h2>\n",
    "If this is the first time the pipeline is running on this machine, just run the cell below. It will copy startup.py from the BEARMIND folder into your local startup folder. This allows the code in startup.py to be executed automatically after each kernel restart (and removes the need to monotonously click through all setup cells after each reloading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "local_startup_dir = get_ipython().profile_dir.startup_dir\n",
    "filedir = os.getcwd()\n",
    "shutil.copy(os.path.join(filedir, 'startup.py'), os.path.join(local_startup_dir, 'startup.py'))\n",
    "%run startup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Module 0</h2>\n",
    "You need to specify the root folder and pathway pattern. Note that * is a wildcard for any symbol combination except slashes (i.e., for any folder name), so it is strongly recommended to use it here.<br/><br/>\n",
    "NB!! Just in case, use double backslashes for folder separation, otherwise some symbols may be interpreted as escape sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = '/export/home1/Test_min_data/'\n",
    "data_path_pattern = '*/*/Miniscope/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GncCQRjb7Olv"
   },
   "source": [
    "<h2>Module 1</h2>\n",
    "Manual video inspection. <br/>Open folder with miniscopic videos in a pop-up window, wait for loading and specify margins to be cropped by sliders or by keyboard, then save them by running the next cell. At the time, cropping .pickle files are to be created in these folders. Repeat for all folders with miniscopic videos you would like to analyze.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Manual file selection:\n",
    "fnames = list(askopenfilenames(title = 'Select files for inspection', initialdir = root, filetypes = [('AVI files', '.avi')]))\n",
    "#OR, alternatively, you can use Automatic file selection\n",
    "#fnames = glob(path + data_path_pattern + '*.avi')\n",
    "\n",
    "data = LoadSelectedVideos(fnames)\n",
    "w = DrawCropper(data, fname=fnames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQSrg0k7Ol7"
   },
   "source": [
    "Batch cropping and timestamp extraction.<br/>Miniscopic videos from folders with .pickle files are to be cropped and saved as _CR.tif in the root folder. There is no need for renaming of sigle-digit .avi files (like 0-9.avi to 00-09.avi)!<br/>\n",
    "Also, along with video data, timestamps are to be copied from minicopic folders to the root folder. Do not delete them, they are nessesary for the further steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Batch crop\n",
    "pick_names = glob(root + data_path_pattern + '*cropping.pickle')\n",
    "\n",
    "for name in pick_names:\n",
    "    out_name = name[len(root): len(os.path.dirname(name))].replace(os.path.sep, '_') \n",
    "    DoCropAndRewrite(name, root + out_name + '.tif')\n",
    "    #copy timestamps from Miniscope folder to the root folder\n",
    "    tst_name = os.path.join(os.path.dirname(name), 'timeStamps.csv')\n",
    "    shutil.copy(tst_name, root + out_name + '_timestamp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 2</h2>\n",
    "Batch motion correction.<br/>All _CR.tif files in the root folder are to be automatically motion corrected with NoRMCorre routine [Pnevmatikakis, Giovanucci, 2017] with the parameters below and saved as _MC.tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatic file selection\n",
    "#fnames = glob(root + data_path_pattern + '*_CR.tif')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "fnames = askopenfilenames(title = 'Select files for motion correction', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "mc_dict = {\n",
    "    'pw_rigid': False,         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "    'max_shifts': (35, 35),    # maximum allowed rigid shift\n",
    "    'gSig_filt': (8, 8),       # size of high pass spatial filtering, used in 1p data\n",
    "    'strides': (48, 48),       # start a new patch for pw-rigid motion correction every x pixels\n",
    "    'overlaps': (24, 24),      # overlap between pathes (size of patch strides+overlaps)\n",
    "    'max_deviation_rigid': 15,  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "    'border_nan': 'copy',      # replicate values along the boundaries\n",
    "    'use_cuda': True,          # Set to True in order to use GPU\n",
    "    'memory_fact': MACHINE_CONFIG['RAM']/16.0,          # How much memory to allocate. 1 works for 16Gb, so 0.8 showd be optimized for 12Gb.\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,          # for parallelization split the movies in  num_splits chuncks across time\n",
    "                               # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None} # intervals at which patches are laid out for motion correction  \n",
    "\n",
    "for name in tqdm.tqdm(fnames):\n",
    "    DoMotionCorrection(name, mc_dict)\n",
    "    CleanMemmaps(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Module 2.5 (optional)</h3>\n",
    "\n",
    "Pre-test of various values of <i>gSig</i> parameter, which is used in the Module 3 and corresponds to a typical radius of a neuron in pixels.<br/>You can play with this parameter but you can use the default value of gSig = 6 as well. <br/> Calculation may take a while, so be patient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gSig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = askopenfilenames(title = 'Select files for gsig testing', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "print(fnames[0])\n",
    "Test_gSig_Range(fnames[0],default_gsig = 3, maxframes = 2000)  # maxframes is the amount of frames taken into account, by default the whole file is to be taken, which may be too slow for large files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_corr and min_pnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "#fnames = glob(os.path.join(root, '*_MC.tif'))\n",
    "fnames = askopenfilenames(title = 'Select files for corr image testing',initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "opt_gsig=5\n",
    "test_min_corr_and_pnr(fnames[0], opt_gsig, start_frame=2000, end_frame=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Module 3</h2>\n",
    "Batch cnmf.<br/>All _MC.tif files in the root folder are to be automatically processed with CaImAn routine [Giovanucci et al., 2019] with the parameters below. Main parameters are gSig and gSiz for cell augmentation, then min_SNR as traces quality threshold. At the end, _estimates.pickle files are to be produced in the root folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSig=5\n",
    "min_corr = 0.85\n",
    "min_pnr = 6\n",
    "gSiz = gSig*4+1\n",
    "cnmf_dict= {'fr': 20,                   # frame rate, frames per second (NOW RECALCULATED FOR EACH FILE FROM TIMESTAMP DATA)\n",
    "            'decay_time': 1,            # typical duration of calcium transient \n",
    "            'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "            'K': None,                  # upper bound on number of components per patch, in general None\n",
    "            'gSig': (gSig, gSig),       # gaussian HALF-width of a 2D gaussian kernel (in pixels), which approximates a neuron\n",
    "            'gSiz': (gSiz, gSiz),       # maximal radius of a neuron in pixels\n",
    "            'merge_thr': 0.8,           # merging threshold, max correlation allowed\n",
    "            'p': 1,                     # order of the autoregressive system\n",
    "            'tsub': 1,                  # downsampling factor in time for initialization\n",
    "            'ssub': 1,                  # downsampling factor in space for initialization\n",
    "            'rf': 40,                   # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "            'stride': 25,               # amount of overlap between the patches in pixels(keep it at least large as gSiz, i.e 4 times the neuron size gSig) \n",
    "            'only_init': True,          # set it to True to run CNMF-E\n",
    "            'nb': 0,                    # number of background components (rank) if positive, else exact ring model with following settings: nb= 0: Return background as b and W, gnb=-1: Return full rank background B, gnb<-1: Don't return background\n",
    "            'nb_patch': 0,              # number of background components (rank) per patch if nb>0, else it is set automatically\n",
    "            'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "            'low_rank_background': None,           # None leaves background of each patch intact, True performs global low-rank approximation if gnb>0\n",
    "            'update_background_components': True,  # sometimes setting to False improve the results\n",
    "            'min_corr': min_corr,                        # min peak value from correlation image\n",
    "            'min_pnr': min_pnr,                         # min peak to noise ratio from PNR image\n",
    "            'normalize_init': False,               # just leave as is\n",
    "            'center_psf': True,                    # leave as is for 1 photon\n",
    "            'ssub_B': 2,                           # additional downsampling factor in space for background\n",
    "            'ring_size_factor': 1.5,               # radius of ring is gSiz*ring_size_factor\n",
    "            'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "            'border_pix': 5,                       # number of pixels to not consider in the borders\n",
    "            'min_SNR': 3,                          # adaptive way to set threshold on the transient size\n",
    "            'rval_thr': 0.95,                      # threshold on space consistency           \n",
    "            'use_cnn': False}                      # whether to use CNNs for event detection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(os.path.join(root, '*_MC.tif'))\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select files for batch cnmf', initialdir = root, filetypes = [('TIFF files', '.tif')])\n",
    "\n",
    "for name in tqdm.tqdm(fnames):\n",
    "\n",
    "    out_name = name[:-4-6] + f'_estimates.pickle'\n",
    "    print(out_name)\n",
    "    DoCNMF(name,\n",
    "           cnmf_dict,\n",
    "           out_name=out_name,\n",
    "           verbose=True)\n",
    "    \n",
    "    #CleanMemmaps(name)  \n",
    "    err_cnt = 0\n",
    "    while err_cnt < 100:\n",
    "        try:\n",
    "            CleanMemmaps(name)\n",
    "            break\n",
    "        except PermissionError:\n",
    "            time.sleep(1)\n",
    "            err_cnt += 1\n",
    "    print('CleanMemmaps attemps:', err_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnAjhqtm7Ol8"
   },
   "source": [
    "<h2>Module 4</h2>\n",
    "User inspection of cnmf results.<br/>\n",
    "Btw, at this stage, previously saved timestamps are to be merged with cnmf results.\n",
    "By running the section below, you will be prompted to select estimtes file with cnmf results and then to interactively examine detected units (you can select both spatial and temporal components), you can select, merge and delete them, also you can seed new neurons (by PointDrawTool) for further re-run of CNMF with saved seeds. Finally, you can save (by pressing 'Save Results') spatial and temporal components as .tif and traces.csv files, respectively. Spatial components (aka filters) are to be stored in a separate folder (*_filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = askopenfilename(title = 'Select estimates file for examination',\n",
    "                        initialdir = root,\n",
    "                        filetypes = [('estimates files', '*estimates.pickle')])\n",
    "\n",
    "bkapp_kwargs = {\n",
    "    'start_frame': 0,          # start from this frame\n",
    "    'end_frame': 90000,          # end at this frame\n",
    "    'downsampling': 5,           # take every 'x' frame\n",
    "    'fill_alpha': 1,       # selected neuron transparency\n",
    "    'ns_alpha': 0.3,         # non-selected neuron transparency\n",
    "    'line_width': 1.5,         # border width\n",
    "    'cthr': 0.8,             # coutour_thr from caiman (% of signal inside a patch), affects patch size\n",
    "    'line_alpha': 1,           # border transparency\n",
    "    'trace_line_width': 2,       # trace line width\n",
    "    'trace_alpha': 1,          # trace transparency\n",
    "    'size': 900,                #height of the plot\n",
    "    'button_width': 120,         # button width in pixels\n",
    "    'verbose': 0,\n",
    "    'enable_gpu_backend': 1,\n",
    "    'emergency_mode': 0            #simple loading mode in case of slow performance due to large data amount \n",
    "}\n",
    "ExamineCells(fname, default_fps=20, bkapp_kwargs=bkapp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G08W3pnX7OmB"
   },
   "source": [
    "<h2>Module 5 (optional)</h2>\n",
    "Batch detection of significant calcium events. <br/>\n",
    "INPUT: (timestamped) cnmf raw traces as *_traces.csv files<br/>\n",
    "OUTPUT: detected events as *_spikes.csv files; pickles with events (cell-wise list of event-wise lists with dictionaries) and also, interactive .html plot with traces and events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Fitting event detection</h3>\n",
    "Each peak higher than the threshold value is fitted by bi-exponential calcium event waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "#OR, alternatively, you can use manual file selection:\n",
    "#fnames = askopenfilenames(title = 'Select traces for event detection', initialdir = root, filetypes = [('traces files', '*traces.csv')])\n",
    "\n",
    "sd_dict = {'thr': 4,        #threshold for peaks in Median Absolute Deviations (MADs)                    \n",
    "           'sigma' : 7,     #smoothing parameter for peak detection, frames \n",
    "           'est_ton' : 0.5, #estimated event rising time, s \n",
    "           'est_toff' : 2,  #estimated event decay time, s \n",
    "           'draw_details': True} #whether to draw smoothed traces, peaks, pits and fits  \n",
    " \n",
    "for name in fnames: \n",
    "    FitEvents(name, opts = sd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Wavelet event detection</h3>\n",
    "Alternative way of event detection, using wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = askopenfilenames(title = 'Select traces for event detection', initialdir = root, filetypes = [('traces files', '*traces.csv')])\n",
    "\n",
    "wvt_param_dict = {'fps': 20,        # fps, frames                   \n",
    "                  'sigma' : 8,      # smoothing parameter for peak detection, frames\n",
    "                  'beta' : 2,       # Generalized Morse Wavelet parameter, FIXED\n",
    "                  'gamma' : 3,      # Generalized Morse Wavelet parameter, FIXED\n",
    "                  'eps': 10,         # spacing beween consecutive events, frames\n",
    "                  'manual_scales': np.logspace(2.5,5.5,50, base=2),\n",
    "\n",
    "                  # ridge filtering params\n",
    "                  'scale_length_thr': 40,  # min number of scales where ridge is present thr, higher = less events. max=len(manual_scales)\n",
    "                  'max_scale_thr': 7,      # index of a scale with max ridge intensity thr, higher = less events. < 5 = noise, > 20 = huge events\n",
    "                  'max_ampl_thr': 0.075,    # max ridge intensity thr, higher = less events. < 5 = noise, > 20 = huge events\n",
    "                  'max_dur_thr': 200,      # max event duration thr, higher = more events (but probably strange ones)\n",
    "}\n",
    "for fname in fnames:\n",
    "    GetWaveletEvents(fname, opts = wvt_param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, just in case, you may draw existed pairs of traces and events right here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(root + '*traces.csv')\n",
    "for name in fnames:\n",
    "    DrawSpEvents(name, name.replace('traces','spikes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw two types of events simultaneously\n",
    "fnames = glob(root + '*traces.csv')\n",
    "for name in fnames:\n",
    "    DrawSpEvents2(name, name.replace('traces','spikes'), name.replace('traces','wvt_spikes'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0425e94652264a39ab474dac975c6b86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f80f083a8d412ba98f094104f58a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704f6bdddae74c30a20cbcd2e3401a7c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0425e94652264a39ab474dac975c6b86",
      "msg_id": "",
      "outputs": []
     }
    },
    "74cb7943da364f88813682c21b185ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "835d7ae0d557435198ba1aec6c9391ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c78ea570615644abacd263f0cd68dcc7",
       "IPY_MODEL_d034447370f049b695e7587856fbcada"
      ],
      "layout": "IPY_MODEL_74cb7943da364f88813682c21b185ef4"
     }
    },
    "84b51326a2f74869906ed95583092492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c78ea570615644abacd263f0cd68dcc7": {
     "model_module": "jupyter_rfb",
     "model_module_version": "^0.1.0",
     "model_name": "RemoteFrameBufferModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter_rfb",
      "_model_module_version": "^0.1.0",
      "_model_name": "RemoteFrameBufferModel",
      "_view_count": null,
      "_view_module": "jupyter_rfb",
      "_view_module_version": "^0.1.0",
      "_view_name": "RemoteFrameBufferView",
      "css_height": "300px",
      "css_width": "500px",
      "frame_feedback": {},
      "has_visible_views": false,
      "layout": "IPY_MODEL_7aad0af5bc3441f5ac84d3c4a49067f9",
      "resizable": true
     }
    },
    "d034447370f049b695e7587856fbcada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "dimension: t",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_30f80f083a8d412ba98f094104f58a58",
      "max": 499,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_84b51326a2f74869906ed95583092492",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
